{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA RTX 5000 Ada Generation\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.cuda.device_count())  # Should return the number of GPUs\n",
    "print(torch.cuda.get_device_name(0))  # Should show the GPU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"D:/huggingface_cache\" \n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"D:/huggingface_cache\"\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = \"D:/huggingface_cache\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_HOME: D:/huggingface_cache\n",
      "TRANSFORMERS_CACHE: D:/huggingface_cache\n",
      "HUGGINGFACE_HUB_CACHE: D:/huggingface_cache\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"HF_HOME:\", os.getenv(\"HF_HOME\"))\n",
    "print(\"TRANSFORMERS_CACHE:\", os.getenv(\"TRANSFORMERS_CACHE\"))\n",
    "print(\"HUGGINGFACE_HUB_CACHE:\", os.getenv(\"HUGGINGFACE_HUB_CACHE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\openfl\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"#\")\n",
    "# Don't forget to remove the Key when uploading to GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.48s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"cuda\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "prompt = \"\"\" I have the following paragraph, could you generate me a single question and answer from it? \n",
    "\n",
    "Wikipedia is a free online encyclopedia that anyone can edit, and millions already have.\n",
    "Wikipedia's purpose is to benefit readers by presenting information on all branches of knowledge. Hosted by the Wikimedia Foundation, Wikipedia consists of freely editable content, with articles that usually contain numerous links guiding readers to more information.\n",
    "\n",
    "I would like the answer to be in a JSON format \n",
    "\n",
    "Response Format:\n",
    "[\n",
    "    {{\"question\": \"What is ...?\", \"answer\": \"The answer is ...\"}},\n",
    "    {{\"question\": \"How does ... work?\", \"answer\": \"It works by ...\"}}\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_tokens = model.generate(**inputs, max_length=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_tokens = output_tokens[0][len(inputs[\"input_ids\"][0]):]  \n",
    "generated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I would like the questions to be related to the paragraph, and the answers to be concise and to the point. I would also like the questions to be in the form of a question, and the answers to be in the form of a sentence. I would like the questions and answers to be in English.\\n\\nI would like the questions and answers to be related to the paragraph, and the answers to be concise and to the point. I would also like the questions to be in the form of a question, and the answers to be in the form of a sentence. I would like the questions and answers to be in English.\\n\\nI would like the questions and answers to be related to the paragraph, and the answers to be concise and to the point. I would also like the questions to be in the form of a question, and the answers to be in the form of a sentence. I would like the questions and answers to be in English.\\n\\nI would like the questions and answers to be related to the paragraph, and the answers to be concise and to the point. I would also like the questions to be in the form of a question, and the answers to be in the form of a sentence. I would like the questions and answers to be in English.\\n\\nI would like the questions and answers to be related to the paragraph, and the answers to be concise and to the point. I would also like the questions to be in the form of a question, and the answers to be in the form of a sentence. I would like the questions and answers to be in English.\\n\\nI would like the questions and answers to be related to the paragraph, and the answers to be concise and to the point. I would also like the questions to be in the form of a question, and the answers to be'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped = generated_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I would like the questions to be related to the paragraph, and the answers to be concise and to the point. I would also like the questions to be in the form of a question, and the answers to be in the form of a sentence. I would like the questions and answers to be in English.\\n\\nI would like the questions and answers to be related to the paragraph, and the answers to be concise and to the point. I would also like the questions to be in the form of a question, and the answers to be in the form of a sentence. I would like the questions and answers to be in English.\\n\\nI would like the questions and answers to be related to the paragraph, and the answers to be concise and to the point. I would also like the questions to be in the form of a question, and the answers to be in the form of a sentence. I would like the questions and answers to be in English.\\n\\nI would like the questions and answers to be related to the paragraph, and the answers to be concise and to the point. I would also like the questions to be in the form of a question, and the answers to be in the form of a sentence. I would like the questions and answers to be in English.\\n\\nI would like the questions and answers to be related to the paragraph, and the answers to be concise and to the point. I would also like the questions to be in the form of a question, and the answers to be in the form of a sentence. I would like the questions and answers to be in English.\\n\\nI would like the questions and answers to be related to the paragraph, and the answers to be concise and to the point. I would also like the questions to be in the form of a question, and the answers to be'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openfl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
